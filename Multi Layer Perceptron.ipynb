{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering info about images at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\images\\train'...\n",
      "Done!\n",
      "Writing images labels info to file at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\training_images_labels.txt'...\n",
      "Done!\n",
      "Gathering info about images at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\images\\test'...\n",
      "Done!\n",
      "Writing images labels info to file at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\testing_images_labels.txt'...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from common.config import get_config\n",
    "\n",
    "from common.generate_images_labels import get_images_labels_list\n",
    "from common.generate_images_labels import write_images_labels_to_file\n",
    "\n",
    "\n",
    "def main():\n",
    "    images_source = 'train'\n",
    "    if images_source not in ['train', 'test']:\n",
    "        print(\"Invalid image-source '{}'!\".format(images_source))\n",
    "        return\n",
    "\n",
    "    images_dir_path = get_config('{}ing_images_dir_path'.format(images_source))\n",
    "    images_labels_path = get_config(\n",
    "        '{}ing_images_labels_path'.format(images_source))\n",
    "\n",
    "    print(\"Gathering info about images at path '{}'...\".format(images_dir_path))\n",
    "    images_labels_list = get_images_labels_list(images_dir_path)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(\"Writing images labels info to file at path '{}'...\".format(\n",
    "        images_labels_path))\n",
    "    write_images_labels_to_file(images_labels_list, images_labels_path)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    images_source = 'test'\n",
    "    if images_source not in ['train', 'test']:\n",
    "        print(\"Invalid image-source '{}'!\".format(images_source))\n",
    "        return\n",
    "\n",
    "    images_dir_path = get_config('{}ing_images_dir_path'.format(images_source))\n",
    "    images_labels_path = get_config(\n",
    "        '{}ing_images_labels_path'.format(images_source))\n",
    "\n",
    "    print(\"Gathering info about images at path '{}'...\".format(images_dir_path))\n",
    "    images_labels_list = get_images_labels_list(images_dir_path)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(\"Writing images labels info to file at path '{}'...\".format(\n",
    "        images_labels_path))\n",
    "    write_images_labels_to_file(images_labels_list, images_labels_path)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program completed successfully !!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Takes a set of images as inputs, transforms them using multiple algorithms to\n",
    "make it suitable for ingestion into ML routines, then finally outputs them\n",
    "to disk.\n",
    "\"\"\"\n",
    "import csv\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from common.config import get_config\n",
    "from common.image_transformation import apply_image_transformation\n",
    "\n",
    "\n",
    "def write_frame_to_file(frame, frame_label, writer):\n",
    "    \"\"\"\n",
    "    Convert the multi-dimensonal array of the image to a one-dimensional one\n",
    "    and write it to a file, along with its label.\n",
    "    \"\"\"\n",
    "   # print(\"Writing frame to file...\")\n",
    "\n",
    "    flattened_frame = frame.flatten()\n",
    "    output_line = [frame_label] + np.array(flattened_frame).tolist()\n",
    "    writer.writerow(output_line)\n",
    "\n",
    "    #print(\"Done!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    images_transformed_path = get_config('images_transformed_path')\n",
    "    with open(images_transformed_path, 'w') as output_file:\n",
    "        writer = csv.writer(output_file, delimiter=',')\n",
    "\n",
    "        training_images_labels_path = get_config('training_images_labels_path')\n",
    "        with open(training_images_labels_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            #print(\"\\n\\n\" + line.strip())\n",
    "            image_path, image_label = line.split()\n",
    "\n",
    "            # Read the input image.\n",
    "            frame = cv2.imread(image_path)\n",
    "            # `frame` is a HxW numpy ndarray of triplets (pixels), where H and W are\n",
    "            # the dimensions of the input image.\n",
    "            # cv2.imshow(\"Original\", frame)\n",
    "            try:\n",
    "                frame = apply_image_transformation(frame)\n",
    "                write_frame_to_file(frame, image_label, writer)\n",
    "            except Exception:\n",
    "                exception_traceback = traceback.format_exc()\n",
    "                print(\"Error while applying image transformation on image path '{}' with the following exception trace:\\n{}\".format(\n",
    "                    image_path, exception_traceback))\n",
    "                continue\n",
    "            # cv2.waitKey(1000)\n",
    "    cv2.destroyAllWindows()\n",
    "    print (\"The program completed successfully !!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from common.config import get_config\n",
    "\n",
    "\n",
    "def print_with_precision(num):\n",
    "    return \"%0.5f\" % num\n",
    "\n",
    "\n",
    "\n",
    "def read_images_transformed(images_transformed_path):\n",
    "    print(\"\\nReading the transformed images file located at path '{}'...\".format(\n",
    "        images_transformed_path))\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open(images_transformed_path) as images_transformed_file:\n",
    "        reader = csv.reader(images_transformed_file, delimiter=',')\n",
    "        cnt = 0\n",
    "        for line in reader:\n",
    "            if len(line)==0:\n",
    "                continue\n",
    "            cnt = cnt + 1\n",
    "            label = line[0]\n",
    "            labels.append(label)\n",
    "            image = line[1:]\n",
    "            image_int = [int(pixel) for pixel in image]\n",
    "            image = np.array(image_int)\n",
    "            images.append(image)\n",
    "    print(\"Done!\\n\")\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def generate_MLP_classifier():\n",
    "    print(\"\\nGenerating MLP model ...\")\n",
    "    # Save the number of columns in predictors: n_cols\n",
    "    n_cols = 900\n",
    "\n",
    "    # Set up the model: model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # Add the first layer\n",
    "#     model.add(Dense(32,activation='relu',input_shape=(n_cols,)))\n",
    "\n",
    "#     # Add the output layer\n",
    "#     model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model = Sequential()\n",
    "    #model.add(Dense(256, activation=\"relu\", input_dim = X_train.shape[1]))\n",
    "    model.add(Dense(1, input_dim = n_cols))\n",
    "\n",
    "    model.compile(loss = \"mse\", optimizer = \"adam\")\n",
    "    print(\"Done!\\n\")\n",
    "    return model\n",
    "\n",
    "def generate_classifier(model_name):\n",
    "    classifier_generator_function_name = \"generate_{}_classifier\".format(\n",
    "        model_name)\n",
    "    return globals()[classifier_generator_function_name]()\n",
    "\n",
    "\n",
    "def divide_data_train_test(images, labels, ratio):\n",
    "    print(\"\\nDividing dataset in the ratio '{}' using `train_test_split()`:\".format(ratio))\n",
    "    ret = train_test_split(images, labels, test_size=ratio, random_state=0)\n",
    "    print(\"Done!\\n\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output directory path: \n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\n",
      "\n",
      "\n",
      "\n",
      "Model stats will be written to the file at path \n",
      "'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\stats-MLP.txt'.\n"
     ]
    }
   ],
   "source": [
    "model_name ='MLP'\n",
    "model_output_dir_path = get_config('model_{}_output_dir_path'.format(model_name))\n",
    "print(\"Model output directory path: \\n\"+model_output_dir_path)\n",
    "model_stats_file_path = os.path.join(model_output_dir_path, \"stats-{}.txt\".format(model_name))\n",
    "print(\"\\n\\n\")\n",
    "print(\"Model stats will be written to the file at path \\n'{}'.\".format(model_stats_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Transformed Path:: \n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\images_transformed.csv\n",
      "\n",
      "Reading the transformed images file located at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\images_transformed.csv'...\n",
      "Done!\n",
      "\n",
      "\n",
      "Dividing dataset in the ratio '0.2' using `train_test_split()`:\n",
      "Done!\n",
      "\n",
      "\n",
      "Training the model...\n",
      "Done!\n",
      "\n",
      "Model Serialized Path \n",
      "\n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\model-serialized-MLP.pkl\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dumping the trained model to disk at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\model-serialized-MLP.pkl'...\n",
      "Dumped\n",
      "\n",
      "\n",
      "Writing model stats to file...\n",
      "[17  3  3  0 14  2  9 15 10  5  0 14  7 15 19  5  4  1 12 10  5 15  4  9  0\n",
      " 15  6 19  2 13  7 11 16 10 14 10 16 13 15  0  4 14 14 10  0  3  7 11  5 17\n",
      " 15  3  5 19 12  2  0  8 12 18 17  9 16  6 18 10  9  7  6 10 16  5  6 16  6\n",
      "  9 17 13 18 14 15  3  2 18  0  9  6  0  6 16 15  6 12  1 14 15 16 15  0 10\n",
      "  4  4 10  1  3 11 19 12  8  0 19  5 19  4 11  7  7  6  6 19 18  9 13  0 10\n",
      " 18 18 10 12 18  1  1  5 13 13  0 17  1  6 16  9 14  5 16  1 17  1  8 11 14\n",
      " 12  6 17  9]\n",
      "Done!\n",
      "\n",
      "\n",
      "Finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def vec_translate(a):\n",
    "    my_dict = {'a':0,'b':1,'d':2,'e':3,'f':4,'g':5,'h':6,'j':7,'k':8,'m':9,\n",
    "               'n':10,'o':11,'p':12,'q':13,'r':14,'s':15,'t':16,'x':17,'y':18,\n",
    "               'z':19}\n",
    "    return np.vectorize(my_dict.__getitem__)(a)\n",
    "\n",
    "with open(model_stats_file_path, \"w\") as model_stats_file:\n",
    "    \n",
    "        images_transformed_path = get_config('images_transformed_path')\n",
    "        print(\"Image Transformed Path:: \\n\"+images_transformed_path)\n",
    "        \n",
    "        images, labels = read_images_transformed(images_transformed_path)\n",
    "        images= StandardScaler().fit_transform(images)\n",
    "        labels=vec_translate(labels)\n",
    "#         labels=pd.get_dummies(labels)\n",
    "#         classifier_model = generate_classifier(model_name)\n",
    "#         model_stats_file.write(\"Model used = '{}'\".format(model_name))\n",
    "#         model_stats_file.write(\"Classifier \\n Model details:\\n{}\\n\\n\".format(classifier_model))\n",
    "#         print('IMAGES\\n\\n')\n",
    "#         all_images=pd.DataFrame(images)\n",
    "#         print('\\n\\n')\n",
    "#         print('LABELS\\n\\n')\n",
    "#         print(labels)\n",
    "        training_images, testing_images, training_labels, testing_labels = divide_data_train_test(images, labels, 0.2)\n",
    "        \n",
    "        print(\"\\nTraining the model...\")\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        clf=MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(50,),random_state=1)\n",
    "        clf.fit(training_images, training_labels)\n",
    "        #classifier_model = classifier_model.fit(training_images, training_labels)\n",
    "        print(\"Done!\\n\")\n",
    "\n",
    "        model_serialized_path = get_config('model_{}_serialized_path'.format(model_name))\n",
    "        print('Model Serialized Path \\n')\n",
    "        print(model_serialized_path)\n",
    "        print('\\n\\n')\n",
    "        print(\"\\nDumping the trained model to disk at path '{}'...\".format(model_serialized_path))\n",
    "#         joblib.dump(classifier_model, model_serialized_path)\n",
    "        joblib.dump(clf, model_serialized_path)\n",
    "        print(\"Dumped\\n\")\n",
    "        #print(clf.summary())\n",
    "        print(\"\\nWriting model stats to file...\")\n",
    "#         score = classifier_model.score(testing_images, testing_labels)\n",
    "        score = clf.score(testing_images, testing_labels)\n",
    "        model_stats_file.write(\"Model score:\\n{}\\n\\n\".format(print_with_precision(score)))\n",
    "\n",
    "#         predicted = classifier_model.predict(testing_images)\n",
    "        predicted = clf.predict(testing_images)\n",
    "        print(predicted)\n",
    "        report = metrics.classification_report(testing_labels, predicted)\n",
    "        model_stats_file.write(\"Classification report:\\n{}\\n\\n\".format(report))\n",
    "        print(\"Done!\\n\")\n",
    "\n",
    "        print(\"\\nFinished!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output directory path: \n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\n",
      "\n",
      "\n",
      "\n",
      "Model stats will be written to the file at path \n",
      "'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\stats-MLP.txt'.\n",
      "Image Transformed Path:: \n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\images_transformed.csv\n",
      "\n",
      "Reading the transformed images file located at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\images_transformed.csv'...\n",
      "Done!\n",
      "\n",
      "\n",
      "Dividing dataset in the ratio '0.2' using `train_test_split()`:\n",
      "Done!\n",
      "\n",
      "\n",
      "Training the model...\n",
      "Done!\n",
      "\n",
      "Model Serialized Path \n",
      "\n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\model-serialized-MLP.pkl\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dumping the trained model to disk at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\model-serialized-MLP.pkl'...\n",
      "Dumped\n",
      "\n",
      "\n",
      "Writing model stats to file...\n",
      "[17  3  3  0 14  2  9 15 10  5  0 14  7 15 19  5  4  1 12 10 11 15  4  9  0\n",
      " 15  6 19  2 13  7 11 16 10 10 10  8 13 15  0  4 14 14 10  0  3  9 11  5 17\n",
      " 15  3  5 19 12  2  0  8 12 18 17  9 16  6 15 10  9  0  6 10 16  5  6 16  6\n",
      "  9 17 13 18 14 15  3  2 12  0  9  6 16  6 16 15  6 12  1 14 15 16 15  0 10\n",
      "  4  4 10  1  6 11 19 12  8  0 19  5 15  4 11  7  7  6  6 19 18  9  3 15 10\n",
      " 18 18 10 12 18  1  1  5 10 13  5 17  1  6  9  9 14  5  2  1 17  1  8 11 10\n",
      " 12  6 17  9]\n",
      "Done!\n",
      "\n",
      "\n",
      "Finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'MLP_Double_Layer'\n",
    "model_name='MLP'\n",
    "model_output_dir_path = get_config('model_{}_output_dir_path'.format(model_name))\n",
    "print(\"Model output directory path: \\n\"+model_output_dir_path)\n",
    "model_stats_file_path = os.path.join(model_output_dir_path, \"stats-{}.txt\".format(model_name))\n",
    "print(\"\\n\\n\")\n",
    "print(\"Model stats will be written to the file at path \\n'{}'.\".format(model_stats_file_path))\n",
    "import pandas as pd\n",
    "def vec_translate(a):\n",
    "    my_dict = {'a':0,'b':1,'d':2,'e':3,'f':4,'g':5,'h':6,'j':7,'k':8,'m':9,\n",
    "               'n':10,'o':11,'p':12,'q':13,'r':14,'s':15,'t':16,'x':17,'y':18,\n",
    "               'z':19}\n",
    "    return np.vectorize(my_dict.__getitem__)(a)\n",
    "\n",
    "with open(model_stats_file_path, \"w\") as model_stats_file:\n",
    "    \n",
    "        images_transformed_path = get_config('images_transformed_path')\n",
    "        print(\"Image Transformed Path:: \\n\"+images_transformed_path)\n",
    "        \n",
    "        images, labels = read_images_transformed(images_transformed_path)\n",
    "        images= StandardScaler().fit_transform(images)\n",
    "        labels=vec_translate(labels)\n",
    "#         labels=pd.get_dummies(labels)\n",
    "#         classifier_model = generate_classifier(model_name)\n",
    "#         model_stats_file.write(\"Model used = '{}'\".format(model_name))\n",
    "#         model_stats_file.write(\"Classifier \\n Model details:\\n{}\\n\\n\".format(classifier_model))\n",
    "#         print('IMAGES\\n\\n')\n",
    "#         all_images=pd.DataFrame(images)\n",
    "#         print('\\n\\n')\n",
    "#         print('LABELS\\n\\n')\n",
    "#         print(labels)\n",
    "        training_images, testing_images, training_labels, testing_labels = divide_data_train_test(images, labels, 0.2)\n",
    "        \n",
    "        print(\"\\nTraining the model...\")\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        clf=MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(50,50),random_state=1)\n",
    "        clf.fit(training_images, training_labels)\n",
    "        #classifier_model = classifier_model.fit(training_images, training_labels)\n",
    "        print(\"Done!\\n\")\n",
    "\n",
    "        model_serialized_path = get_config('model_{}_serialized_path'.format(model_name))\n",
    "        print('Model Serialized Path \\n')\n",
    "        print(model_serialized_path)\n",
    "        print('\\n\\n')\n",
    "        print(\"\\nDumping the trained model to disk at path '{}'...\".format(model_serialized_path))\n",
    "#         joblib.dump(classifier_model, model_serialized_path)\n",
    "        joblib.dump(clf, model_serialized_path)\n",
    "        print(\"Dumped\\n\")\n",
    "        #print(clf.summary())\n",
    "        print(\"\\nWriting model stats to file...\")\n",
    "#         score = classifier_model.score(testing_images, testing_labels)\n",
    "        score = clf.score(testing_images, testing_labels)\n",
    "        model_stats_file.write(\"Model score:\\n{}\\n\\n\".format(print_with_precision(score)))\n",
    "\n",
    "#         predicted = classifier_model.predict(testing_images)\n",
    "        predicted = clf.predict(testing_images)\n",
    "        print(predicted)\n",
    "        report = metrics.classification_report(testing_labels, predicted)\n",
    "        model_stats_file.write(\"Classification report:\\n{}\\n\\n\".format(report))\n",
    "        print(\"Done!\\n\")\n",
    "\n",
    "        print(\"\\nFinished!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output directory path: \n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\n",
      "\n",
      "\n",
      "\n",
      "Model stats will be written to the file at path \n",
      "'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\stats-MLP.txt'.\n",
      "Image Transformed Path:: \n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\images_transformed.csv\n",
      "\n",
      "Reading the transformed images file located at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\images_transformed.csv'...\n",
      "Done!\n",
      "\n",
      "\n",
      "Dividing dataset in the ratio '0.2' using `train_test_split()`:\n",
      "Done!\n",
      "\n",
      "\n",
      "Training the model...\n",
      "Done!\n",
      "\n",
      "Model Serialized Path \n",
      "\n",
      "C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\model-serialized-MLP.pkl\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dumping the trained model to disk at path 'C:\\Users\\Subham\\Documents\\Indian-Sign-Language\\data\\generated\\output\\MLP\\model-serialized-MLP.pkl'...\n",
      "Dumped\n",
      "\n",
      "\n",
      "Writing model stats to file...\n",
      "[17  3  3  0 14  2  9 15 10  5  0 14  7 15 19  5  4  1 12  9 11 15  4  9 16\n",
      " 15  6 19  2 13  7 11 16 10 14 10 16 13 15 10  4  9 14 10 10  3 16 11  5 17\n",
      " 15  3  5 19 12  2  0  8 12 18 17  9 16  6  8 10  9  7  6 10 16  5  6 16  6\n",
      "  9 17 13 18 14 15  3  2  8 19  9  6  0  6 16 15  6  8  1 14 14 13 15  0 10\n",
      "  4  4 10  1  3 11 19 12 19  0 19  5 15  4 11  7  7  6  6 19 18  9 13 10 10\n",
      " 18 18 10 12 18  1  1  5 10 13 10 17  1  6 16  9 14  5  2  1 17  1  8 11  9\n",
      " 12  6 17  9]\n",
      "Done!\n",
      "\n",
      "\n",
      "Finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'MLP_Triple_Layer'\n",
    "model_name = 'MLP'\n",
    "model_output_dir_path = get_config('model_{}_output_dir_path'.format(model_name))\n",
    "print(\"Model output directory path: \\n\"+model_output_dir_path)\n",
    "model_stats_file_path = os.path.join(model_output_dir_path, \"stats-{}.txt\".format(model_name))\n",
    "print(\"\\n\\n\")\n",
    "print(\"Model stats will be written to the file at path \\n'{}'.\".format(model_stats_file_path))\n",
    "import pandas as pd\n",
    "def vec_translate(a):\n",
    "    my_dict = {'a':0,'b':1,'d':2,'e':3,'f':4,'g':5,'h':6,'j':7,'k':8,'m':9,\n",
    "               'n':10,'o':11,'p':12,'q':13,'r':14,'s':15,'t':16,'x':17,'y':18,\n",
    "               'z':19}\n",
    "    return np.vectorize(my_dict.__getitem__)(a)\n",
    "\n",
    "with open(model_stats_file_path, \"w\") as model_stats_file:\n",
    "    \n",
    "        images_transformed_path = get_config('images_transformed_path')\n",
    "        print(\"Image Transformed Path:: \\n\"+images_transformed_path)\n",
    "        \n",
    "        images, labels = read_images_transformed(images_transformed_path)\n",
    "        images= StandardScaler().fit_transform(images)\n",
    "        labels=vec_translate(labels)\n",
    "#         labels=pd.get_dummies(labels)\n",
    "#         classifier_model = generate_classifier(model_name)\n",
    "#         model_stats_file.write(\"Model used = '{}'\".format(model_name))\n",
    "#         model_stats_file.write(\"Classifier \\n Model details:\\n{}\\n\\n\".format(classifier_model))\n",
    "#         print('IMAGES\\n\\n')\n",
    "#         all_images=pd.DataFrame(images)\n",
    "#         print('\\n\\n')\n",
    "#         print('LABELS\\n\\n')\n",
    "#         print(labels)\n",
    "        training_images, testing_images, training_labels, testing_labels = divide_data_train_test(images, labels, 0.2)\n",
    "        \n",
    "        print(\"\\nTraining the model...\")\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        clf=MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(50,50,50),random_state=1)\n",
    "        clf.fit(training_images, training_labels)\n",
    "        #classifier_model = classifier_model.fit(training_images, training_labels)\n",
    "        print(\"Done!\\n\")\n",
    "\n",
    "        model_serialized_path = get_config('model_{}_serialized_path'.format(model_name))\n",
    "        print('Model Serialized Path \\n')\n",
    "        print(model_serialized_path)\n",
    "        print('\\n\\n')\n",
    "        print(\"\\nDumping the trained model to disk at path '{}'...\".format(model_serialized_path))\n",
    "#         joblib.dump(classifier_model, model_serialized_path)\n",
    "        joblib.dump(clf, model_serialized_path)\n",
    "        print(\"Dumped\\n\")\n",
    "        #print(clf.summary())\n",
    "        print(\"\\nWriting model stats to file...\")\n",
    "#         score = classifier_model.score(testing_images, testing_labels)\n",
    "        score = clf.score(testing_images, testing_labels)\n",
    "        model_stats_file.write(\"Model score:\\n{}\\n\\n\".format(print_with_precision(score)))\n",
    "\n",
    "#         predicted = classifier_model.predict(testing_images)\n",
    "        predicted = clf.predict(testing_images)\n",
    "        print(predicted)\n",
    "        report = metrics.classification_report(testing_labels, predicted)\n",
    "        model_stats_file.write(\"Classification report:\\n{}\\n\\n\".format(report))\n",
    "        print(\"Done!\\n\")\n",
    "\n",
    "        print(\"\\nFinished!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program completed successfully !!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Takes a set of images as inputs, transforms them using multiple algorithms to\n",
    "make it suitable for ingestion into ML routines, then finally outputs them\n",
    "to disk.\n",
    "\"\"\"\n",
    "import csv\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from common.config import get_config\n",
    "from common.image_transformation import apply_image_transformation\n",
    "\n",
    "\n",
    "def write_frame_to_file(frame, frame_label, writer):\n",
    "    \"\"\"\n",
    "    Convert the multi-dimensonal array of the image to a one-dimensional one\n",
    "    and write it to a file, along with its label.\n",
    "    \"\"\"\n",
    "   # print(\"Writing frame to file...\")\n",
    "\n",
    "    flattened_frame = frame.flatten()\n",
    "    output_line = [frame_label] + np.array(flattened_frame).tolist()\n",
    "    writer.writerow(output_line)\n",
    "\n",
    "    #print(\"Done!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    images_transformed_path = get_config('images_transformed_path')\n",
    "    with open(images_transformed_path, 'w') as output_file:\n",
    "        writer = csv.writer(output_file, delimiter=',')\n",
    "\n",
    "        testing_images_labels_path = get_config('testing_images_labels_path')\n",
    "        with open(testing_images_labels_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            #print(\"\\n\\n\" + line.strip())\n",
    "            image_path, image_label = line.split()\n",
    "\n",
    "            # Read the input image.\n",
    "            frame = cv2.imread(image_path)\n",
    "            # `frame` is a HxW numpy ndarray of triplets (pixels), where H and W are\n",
    "            # the dimensions of the input image.\n",
    "            # cv2.imshow(\"Original\", frame)\n",
    "            try:\n",
    "                frame = apply_image_transformation(frame)\n",
    "                write_frame_to_file(frame, image_label, writer)\n",
    "            except Exception:\n",
    "                exception_traceback = traceback.format_exc()\n",
    "                print(\"Error while applying image transformation on image path '{}' with the following exception trace:\\n{}\".format(\n",
    "                    image_path, exception_traceback))\n",
    "                continue\n",
    "            # cv2.waitKey(1000)\n",
    "    cv2.destroyAllWindows()\n",
    "    print (\"The program completed successfully !!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_input=pd.read_csv('C:\\\\Users\\\\Subham\\\\Documents\\\\Indian-Sign-Language\\\\data\\\\generated\\\\images_transformed.csv',header=None)\n",
    "target=test_input[0]\n",
    "test_input=test_input.drop(0,axis=1)\n",
    "test_input= StandardScaler().fit_transform(test_input)\n",
    "target=vec_translate(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 450\n",
      "Accuracy of MLP Classification on Test Data is: 0.18\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import traceback\n",
    "\n",
    "import cv2\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from common.config import get_config\n",
    "from common.image_transformation import apply_image_transformation\n",
    "import warnings\n",
    "\n",
    "def main():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    model_name = 'MLP'\n",
    "    if model_name not in ['svm', 'logistic', 'knn','DecisionTree','RandomForest','GaussianNB','LinearDiscriminantAnalysis', \n",
    "                      'Bagging' , 'ExtraTrees', 'AdaBoost' , 'Voting','GradientBoosting','MLP']:\n",
    "        print(\"Invalid model-name '{}'!\".format(model_name))\n",
    "        return\n",
    "\n",
    "    #print(\"Using model '{}'...\".format(model_name))\n",
    "\n",
    "    model_serialized_path = get_config(\n",
    "        'model_{}_serialized_path'.format(model_name))\n",
    "    #print(\"Model deserialized from path '{}'\".format(model_serialized_path))\n",
    "\n",
    "    testing_images_labels_path = get_config('testing_images_labels_path')\n",
    "    total=len(target)\n",
    "    cnt=0\n",
    "    classifier_model = joblib.load(model_serialized_path)\n",
    "    predicted_labels = classifier_model.predict(test_input)\n",
    "#     predicted_label = predicted_labels[0]\n",
    "    #print(predicted_labels)\n",
    "    for i in range(total):\n",
    "        if target[i] != predicted_labels[i]:\n",
    "                    cnt += 1\n",
    "    print(str(cnt)+\" \"+str(total))\n",
    "    print(\"Accuracy of \"+model_name+\" Classification on Test Data is: \"+str((total-cnt)/total))\n",
    "    cv2.destroyAllWindows()\n",
    "    #print (\"The program completed successfully !!\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
